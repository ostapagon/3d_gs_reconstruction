{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ca995a8-2112-45b9-bc17-614e21a41475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/app')\n",
    "# sys.path.append('/app/submodules')\n",
    "sys.path.append('/app/submodules/Depth-Anything/metric_depth/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97d4f0ba-e8cc-4a66-93ba-b5962443c6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c93cd2c-88d0-494c-927c-d2cb7e9e28ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import open3d as o3d\n",
    "from tqdm import tqdm\n",
    "from zoedepth.models.builder import build_model\n",
    "from zoedepth.utils.config import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66de5b58-d7a3-4541-96b3-254bbcbb0711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global settings\n",
    "FL = 715.0873\n",
    "FY = 256 * 0.6\n",
    "FX = 256 * 0.6\n",
    "NYU_DATA = False\n",
    "FINAL_HEIGHT = 256\n",
    "FINAL_WIDTH = 256\n",
    "INPUT_DIR = './my_test/input'\n",
    "OUTPUT_DIR = './my_test/output'\n",
    "DATASET = 'nyu' # Lets not pick a fight with the model's dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "defbd007-1ea5-422f-8699-3918e8e5dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(model):\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "    image_paths = glob.glob(os.path.join(INPUT_DIR, '*.png')) + glob.glob(os.path.join(INPUT_DIR, '*.jpg'))\n",
    "    for image_path in tqdm(image_paths, desc=\"Processing Images\"):\n",
    "        try:\n",
    "            color_image = Image.open(image_path).convert('RGB')\n",
    "            original_width, original_height = color_image.size\n",
    "            image_tensor = transforms.ToTensor()(color_image).unsqueeze(0).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "            pred = model(image_tensor, dataset=DATASET)\n",
    "            if isinstance(pred, dict):\n",
    "                pred = pred.get('metric_depth', pred.get('out'))\n",
    "            elif isinstance(pred, (list, tuple)):\n",
    "                pred = pred[-1]\n",
    "            pred = pred.squeeze().detach().cpu().numpy()\n",
    "\n",
    "            # Resize color image and depth to final size\n",
    "            resized_color_image = color_image.resize((FINAL_WIDTH, FINAL_HEIGHT), Image.LANCZOS)\n",
    "            resized_pred = Image.fromarray(pred).resize((FINAL_WIDTH, FINAL_HEIGHT), Image.NEAREST)\n",
    "\n",
    "            focal_length_x, focal_length_y = (FX, FY) if not NYU_DATA else (FL, FL)\n",
    "            x, y = np.meshgrid(np.arange(FINAL_WIDTH), np.arange(FINAL_HEIGHT))\n",
    "            x = (x - FINAL_WIDTH / 2) / focal_length_x\n",
    "            y = (y - FINAL_HEIGHT / 2) / focal_length_y\n",
    "            z = np.array(resized_pred)\n",
    "            points = np.stack((np.multiply(x, z), np.multiply(y, z), z), axis=-1).reshape(-1, 3)\n",
    "            colors = np.array(resized_color_image).reshape(-1, 3) / 255.0\n",
    "\n",
    "            pcd = o3d.geometry.PointCloud()\n",
    "            pcd.points = o3d.utility.Vector3dVector(points)\n",
    "            pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "            o3d.io.write_point_cloud(os.path.join(OUTPUT_DIR, os.path.splitext(os.path.basename(image_path))[0] + \".ply\"), pcd)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "119d6357-5c37-44be-9179-b92f9ce56801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model_name, pretrained_resource):\n",
    "    config = get_config(model_name, \"eval\", DATASET)\n",
    "    config.pretrained_resource = pretrained_resource\n",
    "    model = build_model(config).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    process_images(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e518dea5-4c01-4383-83cf-8ea3f28b2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "    model: str = 'zoedepth'\n",
    "    pretrained_resource: str = 'local::/app/checkpoints/depth-anything/depth_anything_metric_depth_indoor.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83a07ea2-10fa-4f8a-8a4c-2c73b95172fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params passed to Resize transform:\n",
      "\twidth:  518\n",
      "\theight:  392\n",
      "\tresize_target:  True\n",
      "\tkeep_aspect_ratio:  False\n",
      "\tensure_multiple_of:  14\n",
      "\tresize_method:  minimal\n",
      "Using pretrained resource local::/app/checkpoints/depth-anything/depth_anything_metric_depth_indoor.pt\n",
      "Loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "args = Args()\n",
    "main(args.model, args.pretrained_resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0199b17d-c0d3-4c89-aac0-3680e295d58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
